{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.10.11\n",
    "\n",
    "import numpy as np # v. 1.22.1\n",
    "from matplotlib import pyplot as plt # v. 3.7.5\n",
    "import os\n",
    "import pandas as pd # v. 1.5.3\n",
    "import seaborn as sns # v. 0.12.2\n",
    "import pykrev as pk # v. 1.2.4\n",
    "import datetime\n",
    "\n",
    "from corems.transient.input.brukerSolarix import ReadBrukerSolarix # v. 1.6.0\n",
    "from corems.encapsulation.factory.parameters import MSParameters\n",
    "from corems.mass_spectrum.calc.Calibration import MzDomainCalibration\n",
    "from corems.molecular_id.search.molecularFormulaSearch import SearchMolecularFormulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory tree is organised as follows:\n",
    "\n",
    "<img src=\"dir_tree.png\" height=500 px/>\n",
    "\n",
    "For the code to work, please modify the variable ```general_dir``` so as to direct the code towards the desired folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the MS data is, with the directory tree shown above.\n",
    "general_dir = '../../MS_data/dummy_31-10-2024'\n",
    "\n",
    "# Important folders and files, without the general_dir prefix\n",
    "spectra_folder = 'ms_files'\n",
    "run_order = 'run_order.csv'\n",
    "ref_file_location = 'Hawkes_neg.ref'\n",
    "param_file = \"parameters.txt\"\n",
    "\n",
    "# Change truth value if you do/don't want them\n",
    "filter_noise = 1\n",
    "calibration = 1\n",
    "logs = 1\n",
    "remove_blanks = 1\n",
    "save = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the general_dir\n",
    "os.chdir(general_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare folder db where the molformulas.sqlite file will be created and stored.\n",
    "db = f'db'\n",
    "if not os.path.exists(db): os.mkdir(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_params(file_name:str,sep='\\n---\\n',comment='#'):\n",
    "    '''\n",
    "    You can use the read_params function to read in the parameters needed to process MS spectra of organic matter.\n",
    "    The parameter file takes the following shape:\n",
    "\n",
    "    ELEMENTAL PARAMETERS:\n",
    "        C: 1, 100\n",
    "        H: 1, 200\n",
    "        O: 0, 26\n",
    "    ---\n",
    "    DBE: 0, 50\n",
    "    ---\n",
    "    PPM ERROR: 1\n",
    "    ---\n",
    "    MODE: -\n",
    "    ---\n",
    "    NOISE THRESHOLD STD: 3\n",
    "    ---\n",
    "    CALIB PPM THRESHOLD:\n",
    "    31/10/2024: -0.1, 2.7\n",
    "    02/11/2024: 0.5, 2\n",
    "    ---\n",
    "    O/C: 0, 1.2\n",
    "    ---\n",
    "    H/C: 0.3, 2.5\n",
    "    ---\n",
    "\n",
    "    Where \"\\\\n---\\\\n\" is the default separator.\n",
    "    You can comment out sections by adding \"#\" at the beginning of the line, though you can also change this by setting the variable comment to something else.\n",
    "    As such, make sure that file_name is a string of literals\n",
    "\n",
    "    '''\n",
    "\n",
    "    assert type(file_name) == str, 'The variable file_name must be a string of literals'\n",
    "    assert type(sep) == str, 'The variable sep must be a string of literals'\n",
    "    assert type(comment) == str, 'The variable comment must be a string of literals'\n",
    "\n",
    "    param_file = open(file_name, \"r\").read().split(sep)\n",
    "    # param_file = param_file.split('\\n---\\n')\n",
    "\n",
    "    elem_dic = {}\n",
    "    elem_ratios_dic = {}\n",
    "\n",
    "    for p in param_file:\n",
    "        if p[0] != comment:\n",
    "            p = p.upper()\n",
    "            if 'ELEMENTAL PARAMETERS' in p:\n",
    "                elem_lim = p.replace(' ','').replace('ELEMENTALPARAMETERS','').replace('\\t','').replace(':\\n','').split('\\n')\n",
    "                for lim in elem_lim:\n",
    "                    if lim[0] != comment:\n",
    "                        lim = lim.split(':')\n",
    "                        lims = lim[1].split(',')\n",
    "                        lims = np.array(lims).astype(int)\n",
    "                        lim_tuple = (int(np.min(lims)),int(np.max(lims)))\n",
    "                        elem_dic[lim[0]] = lim_tuple\n",
    "\n",
    "            elif 'DBE' in p:\n",
    "                dbe_txt = p.replace('DBE:','').replace(' ','')\n",
    "                dbe_txt = dbe_txt.split(',')\n",
    "                dbe_txt = np.array(dbe_txt).astype(int)\n",
    "                dbe = (int(np.min(dbe_txt)),int(np.max(dbe_txt)))\n",
    "\n",
    "            elif 'PPM ERROR:' in p:\n",
    "                ppm_error_txt = p.replace('PPM ERROR:','').replace(' ','')\n",
    "                ppm_error = float(ppm_error_txt)\n",
    "\n",
    "            elif 'MODE:' in p:\n",
    "                mode_txt = p.replace('MODE:','').replace(' ','')\n",
    "                if mode_txt.lower() in ['+','pos','positive','0']:\n",
    "                    mode = False\n",
    "                elif mode_txt.lower() in ['-','neg','negative','1']:\n",
    "                    mode = True\n",
    "\n",
    "            elif 'H/C:' in p:\n",
    "                hc_txt = p.replace('H/C:','').replace(' ','')\n",
    "                hc_txt = hc_txt.split(',')\n",
    "                hc_txt = np.array(hc_txt).astype(float)\n",
    "                elem_ratios_dic['H/C'] = (float(np.min(hc_txt)),float(np.max(hc_txt)))\n",
    "            \n",
    "            elif 'O/C:' in p:\n",
    "                oc_txt = p.replace('O/C:','').replace(' ','')\n",
    "                oc_txt = oc_txt.split(',')\n",
    "                oc_txt = np.array(oc_txt).astype(float)\n",
    "                elem_ratios_dic['O/C'] = (float(np.min(oc_txt)),float(np.max(oc_txt)))\n",
    "\n",
    "            elif 'N/C:' in p:\n",
    "                nc_txt = p.replace('N/C:','').replace(' ','')\n",
    "                nc_txt = nc_txt.split(',')\n",
    "                nc_txt = np.array(nc_txt).astype(float)\n",
    "                elem_ratios_dic['N/C'] = (float(np.min(nc_txt)),float(np.max(nc_txt)))\n",
    "\n",
    "            elif 'NOISE THRESHOLD STD:' in p:\n",
    "                noise_threshold_std_txt = p.replace('NOISE THRESHOLD STD:','').replace(' ','')\n",
    "                noise_threshold_std = float(noise_threshold_std_txt)\n",
    "\n",
    "            elif 'CALIB PPM THRESHOLD:' in p:\n",
    "                if '\\n' not in p:\n",
    "                    calib_ppm_error_threshold_txt = p.replace('CALIB PPM THRESHOLD:','').replace(' ','')\n",
    "                    calib_ppm_error_threshold_txt = calib_ppm_error_threshold_txt.split(',')\n",
    "                    for i in range(len(calib_ppm_error_threshold_txt)):\n",
    "                            calib_ppm_error_threshold_txt[i] = float(calib_ppm_error_threshold_txt[i])\n",
    "                    calib_ppm_error_threshold = (np.min(calib_ppm_error_threshold_txt),np.max(calib_ppm_error_threshold_txt))\n",
    "\n",
    "                else:\n",
    "                    calib_ppm_error_threshold = {}\n",
    "                    calib_ppm_error_threshold_txt = p.replace('CALIB PPM THRESHOLD:\\n','').replace(' ','')\n",
    "\n",
    "                    calib_ppm_error_threshold_txt_split = calib_ppm_error_threshold_txt.split('\\n')\n",
    "\n",
    "                    for txt in calib_ppm_error_threshold_txt_split:\n",
    "                        if txt[0] != comment:\n",
    "                            txt = txt.split(':')\n",
    "                            date = txt[0]\n",
    "\n",
    "                            thresholds = txt[1].split(',')\n",
    "                            thresholds = np.array(thresholds).astype(float)\n",
    "                            thresholds_tuple = (float(np.min(thresholds)),float(np.max(thresholds)))\n",
    "                            calib_ppm_error_threshold[date] = thresholds_tuple\n",
    "\n",
    "\n",
    "    return elem_dic,elem_ratios_dic,dbe,ppm_error,mode,noise_threshold_std,calib_ppm_error_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_dic,elem_ratios_dic,dbe,ppm_error,mode,noise_threshold_std,calib_ppm_error_threshold = read_params(param_file)\n",
    "if not calibration:\n",
    "    ref_file_location = None\n",
    "    ppm_error = 5\n",
    "\n",
    "if save:\n",
    "    csv_folder = f'CSV_files'\n",
    "    if not os.path.exists(csv_folder): os.mkdir(csv_folder)\n",
    "    # csv_save_name = f\"{file_path.replace('.d','')}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spectrum(file_path:str):\n",
    "    '''\n",
    "    Input the path to the \".d\" directory with the Bruker Solarix mass spectral data in it and the corresponding mass spectrum object.\n",
    "\n",
    "    Have a look at https://github.com/Kzra/pykrev/tree/master/docs/corems_with_pykrev by Dr Ezra Kitson for a tutorial example.\n",
    "    '''\n",
    "\n",
    "    bruker_reader = ReadBrukerSolarix(file_path)\n",
    "    bruker_transient = bruker_reader.get_transient()\n",
    "    mass_spectrum = bruker_transient.get_mass_spectrum(plot_result=False, auto_process = True)\n",
    "\n",
    "    return mass_spectrum\n",
    "\n",
    "def calibrate(mass_spectrum,ref_file_location:str,calib_ppm_error_threshold:tuple|list|np.ndarray,order=2):\n",
    "    '''\n",
    "    Calibrate a mass spectrum using a reference file and a ppm error threshold.\n",
    "\n",
    "    Have a look at https://github.com/Kzra/pykrev/tree/master/docs/corems_with_pykrev by Dr Ezra Kitson for a tutorial example.\n",
    "    '''\n",
    "    #intialise internal calibration function\n",
    "    calfn = MzDomainCalibration(mass_spectrum,ref_file_location)\n",
    "    #read reference mass list in Python\n",
    "    ref_mass_list_fmt  = calfn.load_ref_mass_list(ref_file_location)\n",
    "    #pair up calibration points with detected peaks\n",
    "    imzmeas, mzrefs = calfn.find_calibration_points(mass_spectrum, ref_mass_list_fmt, \n",
    "                                                    calib_ppm_error_threshold=calib_ppm_error_threshold,\n",
    "                                                    calib_snr_threshold=10)\n",
    "    #perform the calibration using a second degree polynomial fit\n",
    "    calfn.recalibrate_mass_spectrum(mass_spectrum,imzmeas,mzrefs,order=order)\n",
    "\n",
    "def noise_filter(mass_spectrum):\n",
    "    '''\n",
    "    Filter out electronic noise from the spectrum using the KMD method.\n",
    "\n",
    "    Have a look at https://github.com/Kzra/pykrev/tree/master/docs/corems_with_pykrev by Dr Ezra Kitson for a tutorial example.\n",
    "    '''\n",
    "    km = mass_spectrum.kendrick_mass\n",
    "    kmd = mass_spectrum.kmd\n",
    "\n",
    "    lower = 0.0011232 * km + 0.05\n",
    "    upper = 0.0011232 * km + 0.2\n",
    "            \n",
    "    llimit = kmd <= lower \n",
    "    ulimit = kmd >= upper \n",
    "\n",
    "    noiseWindow = (llimit + ulimit) !=True\n",
    "\n",
    "    print(f\"There are {sum(noiseWindow)} peaks in the noise window.\")\n",
    "\n",
    "    if sum(noiseWindow) >= 100: \n",
    "        nnPercentile = np.percentile(mass_spectrum.abundance[noiseWindow], q = 99) #find intensity matching to 99th percentile (i.e. only 1 % of peaks in noise window have higher intensity than this)\n",
    "        plimit = mass_spectrum.abundance < nnPercentile #find peaks in the spectrum that have a lower intensity than this (returns a boolean array)\n",
    "        filterIndex = np.where(plimit & noiseWindow)[0] #find the index position of peaks in spectrum that have both a lower intensity than the 99th percentile AND are in the noise window\n",
    "        mass_spectrum.filter_by_index(filterIndex) #remove them from the spectrum\n",
    "\n",
    "    print(f\"There are {len(mass_spectrum.mz_exp)} peaks in the filtered spectrum.\")\n",
    "\n",
    "def peak_assignment(mass_spectrum,db:str,sqlite_file='molformulas.sqlite'):\n",
    "    if 'molformulas.sqlite' in os.listdir(db):\n",
    "        os.remove(f'{db}/{sqlite_file}')\n",
    "\n",
    "    SearchMolecularFormulas(mass_spectrum, first_hit = False).run_worker_mass_spectrum()\n",
    "    mass_spectrum.percentile_assigned(report_error=True)\n",
    "\n",
    "def dbe_plot(mz:tuple|list|np.ndarray,dbe:tuple|list|np.ndarray,width:float=None,title:str=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(mz,dbe,width = width)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('$m$/$z$')\n",
    "    ax.set_ylabel('DBE')\n",
    "    return fig, ax\n",
    "\n",
    "def massspectrum_plot(mz:tuple|list|np.ndarray,intensities:tuple|list|np.ndarray,title:str=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(mz,intensities)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('$m$/$z$')\n",
    "    ax.set_ylabel('Intensity')\n",
    "    ax.set_ylim(0)\n",
    "    ax.set_xlim(np.min(mz),np.max(mz))\n",
    "    return fig, ax\n",
    "\n",
    "def blank_removal(blank_df:pd.core.frame.DataFrame,msDf:pd.core.frame.DataFrame):\n",
    "    # blank_spectrum = read_spectrum(blank_path)\n",
    "\n",
    "    # params(blank_spectrum,elem_dic,ppm_error)\n",
    "\n",
    "    # peak_assignment(blank_spectrum,db)\n",
    "    # blank_df = blank_spectrum.to_dataframe()\n",
    "\n",
    "    assigned = blank_df['Molecular Formula'].notnull()\n",
    "    blank_abundance = np.array(blank_df['Peak Height'][assigned])\n",
    "    blank_formula = np.array(blank_df['Molecular Formula'][assigned])\n",
    "\n",
    "    contaminants = blank_abundance / max(blank_abundance) * 100 > 2\n",
    "    blank_formula = np.array(blank_formula)[contaminants]\n",
    "    # Remove contaminant formula from dataframe \n",
    "    ccount = 0 \n",
    "    for bf in blank_formula: \n",
    "        if bf in list(msDf['Molecular Formula']):\n",
    "            ccount += 1 \n",
    "            fidx = list(msDf['Molecular Formula']).index(bf)\n",
    "            pidx = msDf.loc[fidx,'Index']\n",
    "            didx = msDf[msDf['Index'] == pidx].index\n",
    "            msDf.drop(index=didx)\n",
    "    print(f\"{ccount} contaminant formula removed\")\n",
    "\n",
    "def roman_to_integer(roman_no:str)->int:\n",
    "    '''\n",
    "    Convert a roman numeral to its corresponding integer value.\n",
    "    '''\n",
    "    roman_no = roman_no.lower()\n",
    "\n",
    "    tot = roman_no.count('i') + roman_no.count('v') * 5 + roman_no.count('x') * 10 + roman_no.count('l') * 50 + roman_no.count('c') * 100 + roman_no.count('d') * 500 + roman_no.count('m') * 1000\n",
    "    if 'iv' in roman_no: tot -= roman_no.count('iv') * 2\n",
    "    if 'ix' in roman_no: tot -= roman_no.count('ix') * 2\n",
    "    if 'xl' in roman_no: tot -= roman_no.count('xl') * 20\n",
    "    if 'xc' in roman_no: tot -= roman_no.count('xc') * 20\n",
    "    if 'cd' in roman_no: tot -= roman_no.count('cd') * 200\n",
    "    if 'cm' in roman_no: tot -= roman_no.count('cm') * 200\n",
    "\n",
    "    return tot\n",
    "\n",
    "def give_associated_blank_name(replicate:str):\n",
    "    '''\n",
    "    Input the name of the blank replicate in the format \"MeOH-H2O-BLK_[blank numer: 1, 2, 3, ...]_[replicate number: i, ii, iii, ...]_[DD]-[MM]-[YYYY]\"\n",
    "    and get the name of the blank without the replicate number.\n",
    "    '''\n",
    "    replicate = replicate.split('_')\n",
    "    return '_'.join((replicate[0],replicate[1],replicate[-1]))\n",
    "\n",
    "MSParameters.mass_spectrum.threshold_method = 'auto'\n",
    "MSParameters.mass_spectrum.noise_threshold_std = noise_threshold_std\n",
    "MSParameters.ms_peak.peak_min_prominence_percent = .01\n",
    "\n",
    "def search_params(mass_spectrum,elem_dic:dict,ratios:dict,dbe:tuple|list|np.ndarray,ppm_error:int|float,mode:bool):\n",
    "    # Set the location of the molecular formulae database\n",
    "    mass_spectrum.molecular_search_settings.url_database = None #set none if you aren't using the docker database\n",
    "\n",
    "    # Scoring\n",
    "    mass_spectrum.molecular_search_settings.error_method = 'None' \n",
    "    mass_spectrum.molecular_search_settings.score_method = 'prob_score'\n",
    "\n",
    "    # DBE Limits\n",
    "    mass_spectrum.molecular_search_settings.min_dbe = np.min(dbe)\n",
    "    mass_spectrum.molecular_search_settings.max_dbe = np.max(dbe)\n",
    "\n",
    "    # Isotopologue filter\n",
    "    mass_spectrum.molecular_search_settings.use_isotopologue_filter = True\n",
    "    mass_spectrum.molecular_search_settings.min_abun_error = -30\n",
    "    mass_spectrum.molecular_search_settings.max_abun_error = 70\n",
    "\n",
    "    # Mininimum peaks-per-class \n",
    "    mass_spectrum.molecular_search_settings.use_min_peaks_filter = False\n",
    "    # mass_spectrum.molecular_search_settings.min_peaks_per_class = False\n",
    "\n",
    "    # O/C, H/C, and N/C filters:\n",
    "    if 'H/C' in ratios.keys():\n",
    "        mass_spectrum.molecular_search_settings.min_hc_filter = np.min(elem_ratios_dic['H/C'])\n",
    "        mass_spectrum.molecular_search_settings.max_hc_filter = np.max(elem_ratios_dic['H/C'])\n",
    "    if 'O/C' in ratios.keys():\n",
    "        mass_spectrum.molecular_search_settings.min_oc_filter = np.min(elem_ratios_dic['O/C'])\n",
    "        mass_spectrum.molecular_search_settings.max_oc_filter = np.max(elem_ratios_dic['O/C'])\n",
    "    if 'N/C' in ratios.keys() and 'N' in elem_dic.keys():\n",
    "        mass_spectrum.molecular_search_settings.min_oc_filter = np.min(elem_ratios_dic['N/C'])\n",
    "        mass_spectrum.molecular_search_settings.max_oc_filter = np.max(elem_ratios_dic['N/C'])\n",
    "\n",
    "    # Elements defined and their limits\n",
    "    for e in elem_dic:\n",
    "        mass_spectrum.molecular_search_settings.usedAtoms[e] = elem_dic[e]\n",
    "\n",
    "    # mass error limits \n",
    "    mass_spectrum.molecular_search_settings.min_ppm_error = -ppm_error\n",
    "    mass_spectrum.molecular_search_settings.max_ppm_error = ppm_error\n",
    "\n",
    "    # ion type\n",
    "    mass_spectrum.molecular_search_settings.isProtonated = mode\n",
    "    mass_spectrum.molecular_search_settings.isRadical = False\n",
    "    mass_spectrum.molecular_search_settings.isAdduct = False\n",
    "\n",
    "def process_spectra(spectra_files:tuple|list|np.ndarray,blanks_df:pd.core.frame.DataFrame,spectra_dfs:dict,calib_ppm_error_threshold:tuple|list|np.ndarray):\n",
    "    '''\n",
    "    Batch process raw mass spectra into more easily accessible CSV files.\n",
    "\n",
    "    Have a look at https://github.com/Kzra/pykrev/tree/master/docs/corems_with_pykrev by Dr Ezra Kitson for a tutorial example.\n",
    "    '''\n",
    "\n",
    "    for file in spectra_files:\n",
    "        print(f'---------Starting to process {file}---------')\n",
    "\n",
    "        # 1 - Read the spectrum and get mass spectrum object\n",
    "        mass_spectrum = read_spectrum(file)\n",
    "\n",
    "        # Initialise the search parameters that will be used\n",
    "        search_params(mass_spectrum,elem_dic,elem_ratios_dic,dbe,ppm_error,mode)\n",
    "\n",
    "        # 2 - Remove electronic noise\n",
    "        if filter_noise:\n",
    "            noise_filter(mass_spectrum)\n",
    "\n",
    "        # 3 - Calibrate the spectrum based on a reference file\n",
    "        if calibration:\n",
    "            print(f'---------Calibration for {file}-------------')\n",
    "            calibrate(mass_spectrum,ref_file_location,calib_ppm_error_threshold)\n",
    "            titles = 'Calibrated'\n",
    "        else: titles = 'Uncalibrated'\n",
    "\n",
    "        print(f\"There are {len(mass_spectrum)} peaks in the {titles} spectrum of {file}\")\n",
    "        \n",
    "        # 4 - Assign peaks to molecular formulas based on the chosen parameters.\n",
    "        peak_assignment(mass_spectrum,db)\n",
    "        msDf = mass_spectrum.to_dataframe()\n",
    "\n",
    "        # 5 - Remove blank formulas\n",
    "        if remove_blanks:\n",
    "            print(f'---------Blank Removal for {file}---------')\n",
    "            for blank in blanks_df['file_name']:\n",
    "                print(f'---------Using {blank}-----')\n",
    "                blank_removal(blanks_df['mass_spectrum'][blanks_df['file_name']==blank].to_numpy()[0],msDf)\n",
    "\n",
    "        # Plot the mass spectrum\n",
    "        fig_spectrum, ax_spectrum = massspectrum_plot(msDf['m/z'],msDf['Peak Height'],title=f'{titles} Mass Spectrum of {file}')\n",
    "\n",
    "        #Plot the error jointplot\n",
    "        jointplot = sns.jointplot(x='m/z', y='m/z Error (ppm)', data = msDf)\n",
    "        jointplot.fig.suptitle(f\"Error Jointplot of {file}\")\n",
    "\n",
    "        # Plot a van Krevelen diagram and a DBE diagram.\n",
    "        if calibration:\n",
    "            fig_vk, ax_vk = plt.subplots()\n",
    "            ax_vk.scatter(msDf['O/C'],msDf['H/C'],marker='.',s=5)\n",
    "            ax_vk.set_xlim(0)\n",
    "\n",
    "            fig_dbe, ax_dbe = dbe_plot(msDf['m/z'],msDf['DBE'],width=ppm_error,title=f'DBE of {file}')\n",
    "\n",
    "        # Save the resulting dataframe into a CSV file\n",
    "        if save:\n",
    "            csv_save_name = f\"{csv_folder}/{file.replace('.d','').replace(spectra_folder+'/','')}.csv\"\n",
    "            msDf.to_csv(csv_save_name)\n",
    "        \n",
    "        spectra_dfs[file.replace('_000001.d','')] = msDf\n",
    "\n",
    "        print(f'---------Finished processing {file}---------\\n')\n",
    "\n",
    "    return spectra_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a log file\n",
    "if logs:\n",
    "    logs_folder = 'logs'\n",
    "    if not os.path.exists(logs_folder): os.mkdir(logs_folder)\n",
    "    \n",
    "    time_str = datetime.datetime.now().strftime(r\"%y-%m-%d_%H-%M\")\n",
    "    logs_title = f'logs_{time_str}.txt'\n",
    "    elem_dic_str = ''\n",
    "    for e in elem_dic:\n",
    "        elem_dic_str+= f'{e}: {elem_dic[e]}\\n'\n",
    "    for r in elem_ratios_dic:\n",
    "        elem_dic_str+= f'{r}: {elem_ratios_dic[r]}\\n'\n",
    "    logs_txt = f'''{elem_dic_str}DBE: {dbe}\n",
    "PPM ERROR: {ppm_error}\n",
    "NOISE THRESHOLD STD: {noise_threshold_std}\n",
    "NOISE FILTERED: {bool(filter_noise)}\n",
    "CALIBRATED: {bool(calibration)}\n",
    "CSV SAVED: {bool(save)}\n",
    "'''\n",
    "    if calib_ppm_error_threshold != None: logs_txt+=f'CALIB PPM THRESHOLD: {calib_ppm_error_threshold}'\n",
    "    with open(f'{logs_folder}/{logs_title}', 'w') as f:\n",
    "        f.write(logs_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the running order CSV\n",
    "run_order_df = pd.read_csv(run_order)\n",
    "run_order_df['file_name'] = [f'{spectra_folder}/{x}_000001.d' for x in run_order_df['sample_name']]\n",
    "for file in run_order_df['file_name']:\n",
    "    assert os.path.exists(file), f'The folder {file} does not seem to exist.'\n",
    "\n",
    "# Extract the dates\n",
    "dates = np.unique(run_order_df['date'])\n",
    "assert len(dates) == len (calib_ppm_error_threshold), 'The number of dates and number of CALIB PPM THRESHOLD values must be the same, as instrument parameters change from day to day'\n",
    "\n",
    "# Extract the fles of the samples\n",
    "samples_csv_df = run_order_df[run_order_df['sample_type'].isin(['sample','srfa','SRFA'])]\n",
    "\n",
    "# Extract the blanks\n",
    "blanks_csv_df = run_order_df[run_order_df['sample_type'].isin(['blank','blk'])].drop(['sample_type', 'associated_blank'], axis=1)\n",
    "associated_blank_arr = []\n",
    "\n",
    "# Check that only the blanks associated with samples will be processed\n",
    "for blank in blanks_csv_df['sample_name']:\n",
    "    associated_blank = give_associated_blank_name(blank)\n",
    "    if associated_blank not in samples_csv_df['associated_blank'].tolist():\n",
    "        blanks_csv_df = blanks_csv_df[blanks_csv_df['sample_name']!=blank]\n",
    "\n",
    "associated_blank_arr = np.zeros((len(blanks_csv_df))).astype(str)\n",
    "for i in range(len(blanks_csv_df['sample_name'].to_numpy())):\n",
    "    associated_blank_arr[i] = blanks_csv_df['sample_name'].to_numpy()[i].replace('i','').replace('v','').replace('__','_')\n",
    "\n",
    "blanks_csv_df['associated_name'] = associated_blank_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the blanks beforehand so that you don't have to do so every time while processing the sample spectra\n",
    "if remove_blanks:\n",
    "    processed_blank = []\n",
    "    for f in blanks_csv_df['file_name']:\n",
    "        print(f'---------Starting to process blank {f}---------')\n",
    "        blank_spectrum = read_spectrum(f)\n",
    "        if filter_noise:\n",
    "            noise_filter(blank_spectrum)\n",
    "        if calibration:\n",
    "            print(f'---------Calibration for {f}-------------')\n",
    "            calibrate(blank_spectrum,ref_file_location,calib_ppm_error_threshold)\n",
    "        \n",
    "        search_params(blank_spectrum,elem_dic,elem_ratios_dic,dbe,ppm_error,mode)\n",
    "        peak_assignment(blank_spectrum,db)\n",
    "        blank_df = blank_spectrum.to_dataframe()\n",
    "        processed_blank.append(blank_df)\n",
    "        print(f'---------Finished processing blank {f}---------\\n')\n",
    "    \n",
    "    # Add the processed blank data to the dataframe\n",
    "    blanks_csv_df['mass_spectrum'] = processed_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dfs = {}\n",
    "\n",
    "# Process the spectra date by date so as to have the correct \n",
    "for date in dates:\n",
    "    samples_csv_df_bydate = samples_csv_df[samples_csv_df['date']==date]\n",
    "    blanks_csv_df_bydate = blanks_csv_df[blanks_csv_df['date']==date]\n",
    "\n",
    "    unique_blanks = np.unique(blanks_csv_df['associated_name'])\n",
    "\n",
    "    # Load the right value for the calibration ppm error threshold\n",
    "    if type(calib_ppm_error_threshold)==dict:\n",
    "        calib_ppm_error_threshold_bydate = calib_ppm_error_threshold[date]\n",
    "    else: calib_ppm_error_threshold_bydate = calib_ppm_error_threshold\n",
    "\n",
    "    # Process the spectra sharing the same blanks together\n",
    "    for blank in unique_blanks:\n",
    "        associated_blank = give_associated_blank_name(blank)\n",
    "        samples_csv_df_bydate_byblk = samples_csv_df_bydate[samples_csv_df_bydate['associated_blank']==associated_blank]\n",
    "        blanks_csv_df_bydate_byblk = blanks_csv_df_bydate[blanks_csv_df_bydate['associated_name']==blank]\n",
    "\n",
    "        # Process the spectra\n",
    "        process_spectra(samples_csv_df_bydate_byblk['file_name'].to_numpy(),blanks_csv_df_bydate_byblk,spectra_dfs,calib_ppm_error_threshold_bydate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study intrinsic error distribution:\n",
    "if not calibration:\n",
    "    keys_idx = 0\n",
    "    keys = list(spectra_dfs.keys())\n",
    "    jointplot = sns.jointplot(x='m/z', y='m/z Error (ppm)', data = spectra_dfs[keys[keys_idx]])\n",
    "    jointplot.fig.suptitle(f\"Error Jointplot of {spectra_dfs[keys[keys_idx]]}\")\n",
    "    plt.axhline(-.1,c='r')\n",
    "    plt.axhline(2.7,c='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
