{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # v. 1.22.1\n",
    "from matplotlib import pyplot as plt # v. 3.7.5\n",
    "import os\n",
    "import pandas as pd # v. 1.5.3\n",
    "import seaborn as sns # v. 0.12.2\n",
    "import pykrev as pk # v. 1.2.4\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append('../mchem_functions')\n",
    "import ms_functions_and_defs as msf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = '../../Data/MS_data/CSV_files'\n",
    "include_srfa = 1\n",
    "formula_filter = 2 # /3, or however many technical replicates of the single biological replicate you have. If 3, 2 is a \"soft\" filter, 3 a \"hard\" filter\n",
    "chosen_date = [''] #date in the format dd-mm-yyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the csv_dir\n",
    "try: os.chdir(csv_dir)\n",
    "except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csv_data_dir = 'processed_csv_data_dir'\n",
    "if not os.path.exists(processed_csv_data_dir): os.mkdir(processed_csv_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "csv_list = []\n",
    "files_list = os.listdir()\n",
    "\n",
    "for f in files_list:\n",
    "    if f.endswith('.csv'):\n",
    "        if chosen_date not in  [[],['']]:\n",
    "            if f.split('_')[-2] in chosen_date:\n",
    "                csv_list.append(f)\n",
    "        else:\n",
    "            csv_list.append(f)\n",
    "\n",
    "if not include_srfa: csv_list = [csv for csv in csv_list if 'SRFA' not in csv.upper()]\n",
    "# csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(date:str,sep='-'):\n",
    "    if sep in date:\n",
    "        month = int(date.split(sep)[1])\n",
    "    else:\n",
    "        month = int(date)\n",
    "\n",
    "    if month in [9,10,11]: return 'Aut'\n",
    "    elif month in [12,1,2]: return 'Win'\n",
    "    elif month in [3,4,5]: return 'Spr'\n",
    "    elif month in [6,7,8]: return 'Sum'\n",
    "\n",
    "def csv_date_path(path:str):\n",
    "    if path.endswith('.csv'): path.replace('.csv','')\n",
    "    \n",
    "    if chosen_date not in [[],[''],'']:\n",
    "        if type(chosen_date) != str:\n",
    "            path += '_'\n",
    "            for s in chosen_date:\n",
    "                path += s\n",
    "                if s != chosen_date[-1]:\n",
    "                    path += '_'\n",
    "            \n",
    "        else: path += f'_{chosen_date}'\n",
    "\n",
    "    path += '.csv'\n",
    "\n",
    "    return path\n",
    "\n",
    "def short_name(longname:str):\n",
    "    new_name = longname.replace('MP-','').replace('-OM','').split('-')\n",
    "\n",
    "    if 'PL' in new_name:\n",
    "        new_name = '-'.join([new_name[0],new_name[1],season(new_name[3])])\n",
    "    elif 'SRFA' in new_name[0].upper(): new_name = '-'.join(new_name)\n",
    "    else:\n",
    "        new_name = '-'.join([new_name[0],new_name[2],season(new_name[4])])\n",
    "    \n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MP-HM-PW-A-15-10-2024-OM', 'MP-HM-PW-D-15-10-2024-OM',\n",
       "       'MP-HM-PW-G-17-10-2024-OM', 'SRFA_08-11-2024'], dtype='<U24')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_names = []\n",
    "for csv in csv_list:\n",
    "    if 'SRFA' in csv.upper():\n",
    "        sample_names.append('_'.join([csv.split('_')[0],csv.split('_')[1]]).upper())\n",
    "    else:\n",
    "        sample_names.append(csv.split('_')[0])\n",
    "\n",
    "sample_names_unique = np.unique(np.array(sample_names))\n",
    "sample_names_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = [short_name(x) for x in sample_names_unique]\n",
    "# short_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_names_unique = sample_names_unique[sample_names_unique=='SRFA_08-11-2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_formulae_dict = {}\n",
    "general_approved_formulae = pk.msTupleDict()\n",
    "\n",
    "for name in sample_names_unique:\n",
    "    replicate_csvs = [csv for csv in csv_list if name in csv]\n",
    "    replicate_formulae_list = []\n",
    "\n",
    "    # mz_TupleDict = pk.msTupleDict()\n",
    "    sample_dataDict = pk.msTupleDict()\n",
    "\n",
    "    if len(replicate_csvs) > 1:\n",
    "        \n",
    "        for csv in replicate_csvs:\n",
    "            csv_df = pd.read_csv(csv)\n",
    "            pk_df = pk.read_corems(csv_df)\n",
    "            csv_split = csv.split('_')\n",
    "\n",
    "            sample_dataDict[str(msf.roman_to_integer(csv_split[1]))] = pk_df\n",
    "\n",
    "        # put the dataDict into an ordination df, so that we can drop certain formulae\n",
    "        ord = sample_dataDict.to_OrdinationMatrix()\n",
    "        \n",
    "        # filter by the number of non-NAN values wanted\n",
    "        formula_filtered = ord.dropna(thresh=formula_filter, axis=1)\n",
    "\n",
    "    else:\n",
    "        csv_df = pd.read_csv(csv)\n",
    "        pk_df = pk.read_corems(csv_df)\n",
    "        sample_dataDict[1] = pk_df\n",
    "        formula_filtered = pd.DataFrame(pk_df.intensity/np.sum(pk_df.intensity),index=pk_df.formula,columns=[1]).T\n",
    "\n",
    "    name = short_name(name)\n",
    "\n",
    "    samples_formulae_dict[name] = {}\n",
    "    samples_formulae_dict[name]['formulae'] = list(formula_filtered.columns)\n",
    "    samples_formulae_dict[name]['assigned_intensities'] = formula_filtered\n",
    "\n",
    "    formula_filtered_arr = formula_filtered.to_numpy()\n",
    "    for i in range(len(formula_filtered_arr[:,0])):\n",
    "        formula_filtered_arr[i,:] = formula_filtered_arr[i,:] / np.nansum(formula_filtered_arr[i,:])\n",
    "\n",
    "    samples_formulae_dict[name]['avg_rel_intensities'] = np.nanmean(formula_filtered_arr,axis=0)\n",
    "\n",
    "    general_approved_formulae[name] = list(formula_filtered.columns)\n",
    "\n",
    "    mzs_dict = pk.msTupleDict()\n",
    "\n",
    "    for f in formula_filtered.columns:\n",
    "        for idx in formula_filtered.index:\n",
    "            if f == list(formula_filtered.columns)[0]:\n",
    "                mzs_dict[idx] = []\n",
    "\n",
    "            if f in sample_dataDict[idx].formula:\n",
    "                mzs_dict[idx].append(sample_dataDict[idx].mz[np.where(np.array(sample_dataDict[idx].formula) == f)][0])\n",
    "\n",
    "            else: mzs_dict[idx].append(np.nan)\n",
    "\n",
    "    mzs_df = pd.DataFrame(mzs_dict.values(),index=mzs_dict.keys(),columns=formula_filtered.columns)\n",
    "\n",
    "    samples_formulae_dict[name]['assigned_m/z'] = mzs_df\n",
    "    samples_formulae_dict[name]['avg_m/z'] = np.nanmean(mzs_df.to_numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df = pk.msTupleDict()\n",
    "\n",
    "for name in samples_formulae_dict.keys():\n",
    "    formulae = general_approved_formulae[name]\n",
    "\n",
    "    general_df[name] = pk.msTuple(formula=formulae,intensity=samples_formulae_dict[name]['avg_rel_intensities'],mz=np.ones(len(formulae)))\n",
    "\n",
    "general_ord_df = general_df.to_OrdinationMatrix()\n",
    "# general_ord_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_replicate_names = []\n",
    "for csv in csv_list:\n",
    "    csv = csv.split('_')\n",
    "    short_replicate_names.append('_'.join([short_name(csv[0]),csv[1]]))\n",
    "\n",
    "all_short_names = np.unique((short_names + short_replicate_names))\n",
    "all_short_names.sort()\n",
    "# all_short_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_intensity_df = pk.msTupleDict()\n",
    "overall_mz_df = pk.msTupleDict()\n",
    "replicate = []\n",
    "\n",
    "for name in all_short_names:\n",
    "\n",
    "    if name in general_approved_formulae.keys():\n",
    "        formulae = general_approved_formulae[name]\n",
    "        intensities = samples_formulae_dict[name]['avg_rel_intensities']\n",
    "        mz = samples_formulae_dict[name]['avg_m/z']\n",
    "        replicate.append(0)\n",
    "    \n",
    "    else:\n",
    "        name_split = name.split('_')\n",
    "        roman_no = str(msf.roman_to_integer(name_split[1]))\n",
    "\n",
    "        formulae = general_approved_formulae[name_split[0]]\n",
    "        intensities = samples_formulae_dict[name_split[0]]['assigned_intensities'].loc[roman_no].to_numpy()\n",
    "        mz = samples_formulae_dict[name_split[0]]['assigned_m/z'].loc[roman_no].to_numpy()\n",
    "\n",
    "        replicate.append(1)\n",
    "\n",
    "    overall_intensity_df[name] = pk.msTuple(formula=formulae,intensity=intensities,mz=np.ones(len(formulae)))\n",
    "    overall_mz_df[name] = pk.msTuple(formula=formulae,intensity=mz,mz=np.ones(len(formulae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dfs_list = [[overall_intensity_df,'overall_intensity_ordination_table'], [overall_mz_df,'overall_mz_ordination_table']]\n",
    "\n",
    "for d in overall_dfs_list:\n",
    "    ord_df = d[0].to_OrdinationMatrix()\n",
    "    ord_df.insert(0, 'replicate_y/n', replicate)\n",
    "\n",
    "    ord_df_path = f'{processed_csv_data_dir}/{d[1]}'\n",
    "    ord_df.to_csv(csv_date_path(ord_df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_areas = msf.vk_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add information about mean element counts, element ratios, and compound class counts\n",
    "avg_elements = {}\n",
    "avg_ratios = {'O/C': [],'H/C': [],'N/C': [],}\n",
    "molec_class_no = {}\n",
    "avg_dbe = []\n",
    "avg_ai = []\n",
    "avg_nosc = []\n",
    "# elem_classes_list = ['CHO','CHNO','CHNOS','CHOS','CHS',]\n",
    "elem_classes = {}\n",
    "avg_gfe = [] # LaRowe et al., 2011\n",
    "\n",
    "for i in range(len(short_names)):\n",
    "\n",
    "    name = short_names[i]\n",
    "    msTuple = general_df[name]\n",
    "\n",
    "    elementdf = pd.DataFrame(pk.element_counts(msTuple))\n",
    "    \n",
    "    for element in elementdf.columns:\n",
    "        if i == 0:\n",
    "            avg_elements[element] = []\n",
    "        \n",
    "        avg_elements[element].append(np.mean(elementdf[element]))\n",
    "    \n",
    "    avg_ratios['O/C'].append(avg_elements['O'][i] / avg_elements['C'][i])\n",
    "    avg_ratios['H/C'].append(avg_elements['H'][i] / avg_elements['C'][i])\n",
    "    avg_ratios['N/C'].append(avg_elements['N'][i] / avg_elements['C'][i])\n",
    "    \n",
    "    #---\n",
    "\n",
    "    elementdf['O/C'] = elementdf['O'] / elementdf['C']\n",
    "    elementdf['H/C'] = elementdf['H'] / elementdf['C']\n",
    "    elementdf['N/C'] = elementdf['N'] / elementdf['C']\n",
    "\n",
    "    tot_formulae = len(elementdf)\n",
    "    vk_sorted = msf.molecclass(elementdf,vk_areas)\n",
    "\n",
    "    for molec_class in vk_sorted:\n",
    "        if i == 0:\n",
    "            molec_class_no[f'{molec_class}_tot'] = []\n",
    "            molec_class_no[f'{molec_class}_%'] = []\n",
    "        \n",
    "        molec_class_no[f'{molec_class}_tot'].append(len(vk_sorted[molec_class]))\n",
    "        molec_class_no[f'{molec_class}_%'].append(100*len(vk_sorted[molec_class])/tot_formulae)\n",
    "        \n",
    "    avg_dbe.append(np.mean(pk.double_bond_equivalent(msTuple)))\n",
    "    avg_ai.append(np.mean(pk.aromaticity_index(msTuple, index_type='rAImod')))\n",
    "\n",
    "    nosc = np.mean(pk.nominal_oxidation_state(msTuple))\n",
    "    avg_nosc.append(nosc)\n",
    "    avg_gfe.append((60.3 - (28.5 * nosc)))\n",
    "\n",
    "    ecompounds, ecounts = pk.compound_class(msTuple, method='ELEM')\n",
    "\n",
    "    ecompounds_unique = np.unique(ecompounds)\n",
    "    for e_class in ecompounds_unique:\n",
    "        if i == 0:\n",
    "            elem_classes[f'{e_class}_tot'] = []\n",
    "            elem_classes[f'{e_class}_%'] = []\n",
    "\n",
    "        # add 0's for those classes which were not present in the previous samples\n",
    "        elif [x for x in elem_classes.keys() if f'{e_class}_' in x] == []:\n",
    "            elem_classes[f'{e_class}_tot'] = [0] * i\n",
    "            elem_classes[f'{e_class}_%'] = [0] * i\n",
    "\n",
    "        elem_classes[f'{e_class}_tot'].append(ecounts[e_class])\n",
    "        elem_classes[f'{e_class}_%'].append(100*ecounts[e_class]/tot_formulae)\n",
    "\n",
    "    # check that all the items in the dict have the same length, if not it's because that elemental class was not presen in ecompounds and must therefore be set to 0\n",
    "    for j in elem_classes:\n",
    "        if len(elem_classes[j]) != i+1:\n",
    "            elem_classes[j].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the meta_data_dict which will be saved to a CSV file\n",
    "meta_data_dict = {}\n",
    "columns_list = []\n",
    "index_list = []\n",
    "\n",
    "for i in range(len(short_names)):\n",
    "    name = short_names[i]\n",
    "    index_list.append(name)\n",
    "\n",
    "    meta_data_dict[name] = []\n",
    "\n",
    "    for e in avg_elements:\n",
    "        if i == 0: columns_list.append(e)\n",
    "        meta_data_dict[name].append(avg_elements[e][i])\n",
    "    \n",
    "    for ratio in avg_ratios:\n",
    "        if i == 0: columns_list.append(ratio)\n",
    "        meta_data_dict[name].append(avg_ratios[ratio][i])\n",
    "\n",
    "    # take care that these are in the right order for the columns_list too\n",
    "    meta_data_dict[name].append(avg_dbe[i])\n",
    "    meta_data_dict[name].append(avg_ai[i])\n",
    "    meta_data_dict[name].append(avg_nosc[i])\n",
    "    meta_data_dict[name].append(avg_gfe[i])\n",
    "    if i == 0:\n",
    "        columns_list += ['avg_dbe','avg_ai','avg_nosc','avg_gfe']\n",
    "\n",
    "    for x in molec_class_no:\n",
    "        if i == 0: columns_list.append(x.lower().replace(' ','_'))\n",
    "        meta_data_dict[name].append(molec_class_no[x][i])\n",
    "\n",
    "meta_data_df = pd.DataFrame(data=meta_data_dict.values(),index=meta_data_dict.keys(),columns=columns_list)\n",
    "\n",
    "meta_data_path = f'{processed_csv_data_dir}/meta_data'\n",
    "meta_data_df.to_csv(csv_date_path(meta_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
