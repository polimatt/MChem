{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # v. 1.22.1\n",
    "from matplotlib import pyplot as plt # v. 3.7.5\n",
    "import os\n",
    "import pandas as pd # v. 1.5.3\n",
    "import seaborn as sns # v. 0.12.2\n",
    "import pykrev as pk # v. 1.2.4\n",
    "import datetime\n",
    "import ms_functions_and_defs as msf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = '../../MS_data/CSV_files'\n",
    "include_srfa = 0\n",
    "formula_filter = 2 # /3, or however many technical replicates of the single biological replicate you have. If 3, 2 is a \"soft\" filter, 3 a \"hard\" filter\n",
    "chosen_date = [''] #date in the format dd-mm-yyyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the csv_dir\n",
    "try: os.chdir(csv_dir)\n",
    "except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csv_data_dir = 'processed_csv_data_dir'\n",
    "if not os.path.exists(processed_csv_data_dir): os.mkdir(processed_csv_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "csv_list = []\n",
    "files_list = os.listdir()\n",
    "\n",
    "for f in files_list:\n",
    "    if f.endswith('.csv'):\n",
    "        if chosen_date not in  [[],['']]:\n",
    "            if f.split('_')[-2] in chosen_date:\n",
    "                csv_list.append(f)\n",
    "        else:\n",
    "            csv_list.append(f)\n",
    "\n",
    "if not include_srfa: csv_list = [csv for csv in csv_list if 'SRFA' not in csv.upper()]\n",
    "# csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(date:str,sep='-'):\n",
    "    if sep in date:\n",
    "        month = int(date.split(sep)[1])\n",
    "    else:\n",
    "        month = int(date)\n",
    "\n",
    "    if month in [9,10,11]: return 'Aut'\n",
    "    elif month in [12,1,2]: return 'Win'\n",
    "    elif month in [3,4,5]: return 'Spr'\n",
    "    elif month in [6,7,8]: return 'Sum'\n",
    "\n",
    "def csv_date_path(path:str):\n",
    "    if path.endswith('.csv'): path.replace('.csv','')\n",
    "    \n",
    "    if chosen_date not in [[],[''],'']:\n",
    "        if type(chosen_date) != str:\n",
    "            path += '_'\n",
    "            for s in chosen_date:\n",
    "                path += s\n",
    "                if s != chosen_date[-1]:\n",
    "                    path += '_'\n",
    "            \n",
    "        else: path += f'_{chosen_date}'\n",
    "\n",
    "    path += '.csv'\n",
    "\n",
    "    return path\n",
    "\n",
    "def short_name(longname:str):\n",
    "    new_name = longname.replace('MP-','').replace('-OM','').split('-')\n",
    "\n",
    "    if 'PL' in new_name:\n",
    "        new_name = '-'.join([new_name[0],new_name[1],season(new_name[3])])\n",
    "    else:\n",
    "        new_name = '-'.join([new_name[0],new_name[2],season(new_name[4])])\n",
    "    \n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = []\n",
    "for csv in csv_list:\n",
    "    sample_names.append(csv.split('_')[0])\n",
    "\n",
    "sample_names_unique = np.unique(np.array(sample_names))\n",
    "# sample_names_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = [short_name(x) for x in sample_names_unique]\n",
    "# short_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csv \u001b[38;5;129;01min\u001b[39;00m replicate_csvs:\n\u001b[0;32m     12\u001b[0m     csv_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv)\n\u001b[1;32m---> 13\u001b[0m     pk_df \u001b[38;5;241m=\u001b[39m \u001b[43mpk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_corems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     csv_split \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     sample_dataDict[\u001b[38;5;28mstr\u001b[39m(msf\u001b[38;5;241m.\u001b[39mroman_to_integer(csv_split[\u001b[38;5;241m1\u001b[39m]))] \u001b[38;5;241m=\u001b[39m pk_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pykrev\\formula\\read_corems.py:50\u001b[0m, in \u001b[0;36mread_corems\u001b[1;34m(corems_df, mass_type, remove_multiply_assigned_peaks, verbose)\u001b[0m\n\u001b[0;32m     48\u001b[0m didx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex([])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m assignedDf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(assignedDf[\u001b[43massignedDf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIndex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m: \n\u001b[0;32m     51\u001b[0m         didx \u001b[38;5;241m=\u001b[39m didx\u001b[38;5;241m.\u001b[39munion(assignedDf[assignedDf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i]\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m     52\u001b[0m assignedDf \u001b[38;5;241m=\u001b[39m assignedDf\u001b[38;5;241m.\u001b[39mdrop(index \u001b[38;5;241m=\u001b[39m didx)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\array_ops.py:290\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    162\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\computation\\expressions.py:241\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples_formulae_dict = {}\n",
    "general_approved_formulae = pk.msTupleDict()\n",
    "\n",
    "for name in sample_names_unique:\n",
    "    sample_dataDict = pk.msTupleDict()\n",
    "    replicate_csvs = [csv for csv in csv_list if name in csv]\n",
    "    replicate_formulae_list = []\n",
    "\n",
    "    # mz_TupleDict = pk.msTupleDict()\n",
    "\n",
    "    for csv in replicate_csvs:\n",
    "        csv_df = pd.read_csv(csv)\n",
    "        pk_df = pk.read_corems(csv_df)\n",
    "        csv_split = csv.split('_')\n",
    "\n",
    "        sample_dataDict[str(msf.roman_to_integer(csv_split[1]))] = pk_df\n",
    "\n",
    "    # put the dataDict into an ordination df, so that we can drop certain formulae\n",
    "    ord = sample_dataDict.to_OrdinationMatrix()\n",
    "    \n",
    "    # filter by the number of non-NAN values wanted\n",
    "    formula_filtered = ord.dropna(thresh=formula_filter, axis=1)\n",
    "\n",
    "    name = short_name(name)\n",
    "\n",
    "    samples_formulae_dict[name] = {}\n",
    "    samples_formulae_dict[name]['formulae'] = list(formula_filtered.columns)\n",
    "    samples_formulae_dict[name]['assigned_intensities'] = formula_filtered\n",
    "\n",
    "    formula_filtered_arr = formula_filtered.to_numpy()\n",
    "    for i in range(len(formula_filtered_arr[:,0])):\n",
    "        formula_filtered_arr[i,:] = formula_filtered_arr[i,:] / np.nansum(formula_filtered_arr[i,:])\n",
    "\n",
    "    samples_formulae_dict[name]['avg_rel_intensities'] = np.nanmean(formula_filtered_arr,axis=0)\n",
    "\n",
    "    general_approved_formulae[name] = list(formula_filtered.columns)\n",
    "\n",
    "    mzs_dict = pk.msTupleDict()\n",
    "\n",
    "    for f in formula_filtered.columns:\n",
    "        for idx in formula_filtered.index:\n",
    "            if f == list(formula_filtered.columns)[0]:\n",
    "                    mzs_dict[idx] = []\n",
    "\n",
    "            if f in sample_dataDict[idx].formula:\n",
    "                mzs_dict[idx].append(sample_dataDict[idx].mz[np.where(np.array(sample_dataDict[idx].formula) == f)][0])\n",
    "\n",
    "            else: mzs_dict[idx].append(np.nan)\n",
    "\n",
    "    mzs_df = pd.DataFrame(mzs_dict.values(),index=mzs_dict.keys(),columns=formula_filtered.columns)\n",
    "\n",
    "    samples_formulae_dict[name]['assigned_m/z'] = mzs_df\n",
    "    samples_formulae_dict[name]['avg_m/z'] = np.nanmean(mzs_df.to_numpy(),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df = pk.msTupleDict()\n",
    "\n",
    "for name in samples_formulae_dict.keys():\n",
    "    formulae = general_approved_formulae[name]\n",
    "\n",
    "    general_df[name] = pk.msTuple(formula=formulae,intensity=samples_formulae_dict[name]['avg_rel_intensities'],mz=np.ones(len(formulae)))\n",
    "\n",
    "general_ord_df = general_df.to_OrdinationMatrix()\n",
    "# general_ord_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_replicate_names = []\n",
    "for csv in csv_list:\n",
    "    csv = csv.split('_')\n",
    "    short_replicate_names.append('_'.join([short_name(csv[0]),csv[1]]))\n",
    "\n",
    "all_short_names = (short_names + short_replicate_names)\n",
    "all_short_names.sort()\n",
    "# all_short_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_intensity_df = pk.msTupleDict()\n",
    "overall_mz_df = pk.msTupleDict()\n",
    "replicate = []\n",
    "\n",
    "for name in all_short_names:\n",
    "\n",
    "    if name in general_approved_formulae.keys():\n",
    "        formulae = general_approved_formulae[name]\n",
    "        intensities = samples_formulae_dict[name]['avg_rel_intensities']\n",
    "        mz = samples_formulae_dict[name]['avg_m/z']\n",
    "        replicate.append(0)\n",
    "    \n",
    "    else:\n",
    "        name_split = name.split('_')\n",
    "        roman_no = str(msf.roman_to_integer(name_split[1]))\n",
    "\n",
    "        formulae = general_approved_formulae[name_split[0]]\n",
    "        intensities = samples_formulae_dict[name_split[0]]['assigned_intensities'].loc[roman_no].to_numpy()\n",
    "        mz = samples_formulae_dict[name_split[0]]['assigned_m/z'].loc[roman_no].to_numpy()\n",
    "\n",
    "        replicate.append(1)\n",
    "\n",
    "    overall_intensity_df[name] = pk.msTuple(formula=formulae,intensity=intensities,mz=np.ones(len(formulae)))\n",
    "    overall_mz_df[name] = pk.msTuple(formula=formulae,intensity=mz,mz=np.ones(len(formulae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dfs_list = [[overall_intensity_df,'overall_intensity_ordination_table'], [overall_mz_df,'overall_mz_ordination_table']]\n",
    "\n",
    "for d in overall_dfs_list:\n",
    "    ord_df = d[0].to_OrdinationMatrix()\n",
    "    ord_df.insert(0, 'replicate_y/n', replicate)\n",
    "\n",
    "    ord_df_path = f'{processed_csv_data_dir}/{d[1]}'\n",
    "    ord_df.to_csv(csv_date_path(ord_df_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_areas = msf.vk_areas\n",
    "# {\n",
    "#     'Carbohydrates':{'O/C':[.56,1.23],'H/C':[1.53,2.2],'N/C':[0,0.07]}, #[[O/C_min,O/C_max],[H/C_min,H/C_max]]\n",
    "#     'Lipids':{'O/C':[.01,.35],'H/C':[1.34,2.18],'N/C':[0,0.126]},\n",
    "#     'Lignins':{'O/C':[.21,.44],'H/C':[.86,1.34]},\n",
    "#     'Tannins':{'O/C':[.16,.84],'H/C':[.7,1.01]},\n",
    "#     'Amino sugars': {'O/C':[.56,.95],'H/C':[1.62,2.35],'N/C':[0.07,0.2]}, #a third item to indicate that this class contains N (put N/C ratio)\n",
    "#     'Peptides':{'O/C':[.17,.48],'H/C':[1.33,1.84],'N/C':[0.126,0.7]},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add information about mean element counts, element ratios, and compound class counts\n",
    "avg_elements = {}\n",
    "avg_ratios = {'O/C': [],'H/C': [],'N/C': [],}\n",
    "molec_class_no = {}\n",
    "avg_dbe = []\n",
    "avg_ai = []\n",
    "avg_nosc = []\n",
    "# elem_classes_list = ['CHO','CHNO','CHNOS','CHOS','CHS',]\n",
    "elem_classes = {}\n",
    "avg_gfe = [] # LaRowe et al., 2011\n",
    "\n",
    "for i in range(len(short_names)):\n",
    "\n",
    "    name = short_names[i]\n",
    "    msTuple = general_df[name]\n",
    "\n",
    "    elementdf = pd.DataFrame(pk.element_counts(msTuple))\n",
    "    \n",
    "    for element in elementdf.columns:\n",
    "        if i == 0:\n",
    "            avg_elements[element] = []\n",
    "        \n",
    "        avg_elements[element].append(np.mean(elementdf[element]))\n",
    "    \n",
    "    avg_ratios['O/C'].append(avg_elements['O'][i] / avg_elements['C'][i])\n",
    "    avg_ratios['H/C'].append(avg_elements['H'][i] / avg_elements['C'][i])\n",
    "    avg_ratios['N/C'].append(avg_elements['N'][i] / avg_elements['C'][i])\n",
    "    \n",
    "    #---\n",
    "\n",
    "    elementdf['O/C'] = elementdf['O'] / elementdf['C']\n",
    "    elementdf['H/C'] = elementdf['H'] / elementdf['C']\n",
    "    elementdf['N/C'] = elementdf['N'] / elementdf['C']\n",
    "\n",
    "    tot_formulae = len(elementdf)\n",
    "    vk_sorted = msf.molecclass(elementdf,vk_areas)\n",
    "\n",
    "    for molec_class in vk_sorted:\n",
    "        if i == 0:\n",
    "            molec_class_no[f'{molec_class}_tot'] = []\n",
    "            molec_class_no[f'{molec_class}_%'] = []\n",
    "        \n",
    "        molec_class_no[f'{molec_class}_tot'].append(len(vk_sorted[molec_class]))\n",
    "        molec_class_no[f'{molec_class}_%'].append(100*len(vk_sorted[molec_class])/tot_formulae)\n",
    "        \n",
    "    avg_dbe.append(np.mean(pk.double_bond_equivalent(msTuple)))\n",
    "    avg_ai.append(np.mean(pk.aromaticity_index(msTuple, index_type='rAImod')))\n",
    "\n",
    "    nosc = np.mean(pk.nominal_oxidation_state(msTuple))\n",
    "    avg_nosc.append(nosc)\n",
    "    avg_gfe.append((60.3 - (28.5 * nosc)))\n",
    "\n",
    "    ecompounds, ecounts = pk.compound_class(msTuple, method='ELEM')\n",
    "\n",
    "    ecompounds_unique = np.unique(ecompounds)\n",
    "    for e_class in ecompounds_unique:\n",
    "        if i == 0:\n",
    "            elem_classes[f'{e_class}_tot'] = []\n",
    "            elem_classes[f'{e_class}_%'] = []\n",
    "\n",
    "        # add 0's for those classes which were not present in the previous samples\n",
    "        elif [x for x in elem_classes.keys() if f'{e_class}_' in x] == []:\n",
    "            elem_classes[f'{e_class}_tot'] = [0] * i\n",
    "            elem_classes[f'{e_class}_%'] = [0] * i\n",
    "\n",
    "        elem_classes[f'{e_class}_tot'].append(ecounts[e_class])\n",
    "        elem_classes[f'{e_class}_%'].append(100*ecounts[e_class]/tot_formulae)\n",
    "\n",
    "    # check that all the items in the dict have the same length, if not it's because that elemental class was not presen in ecompounds and must therefore be set to 0\n",
    "    for j in elem_classes:\n",
    "        if len(elem_classes[j]) != i+1:\n",
    "            elem_classes[j].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the meta_data_dict which will be saved to a CSV file\n",
    "meta_data_dict = {}\n",
    "columns_list = []\n",
    "index_list = []\n",
    "\n",
    "for i in range(len(short_names)):\n",
    "    name = short_names[i]\n",
    "    index_list.append(name)\n",
    "\n",
    "    meta_data_dict[name] = []\n",
    "\n",
    "    for e in avg_elements:\n",
    "        if i == 0: columns_list.append(e)\n",
    "        meta_data_dict[name].append(avg_elements[e][i])\n",
    "    \n",
    "    for ratio in avg_ratios:\n",
    "        if i == 0: columns_list.append(ratio)\n",
    "        meta_data_dict[name].append(avg_ratios[ratio][i])\n",
    "\n",
    "    # take care that these are in the right order for the columns_list too\n",
    "    meta_data_dict[name].append(avg_dbe[i])\n",
    "    meta_data_dict[name].append(avg_ai[i])\n",
    "    meta_data_dict[name].append(avg_nosc[i])\n",
    "    meta_data_dict[name].append(avg_gfe[i])\n",
    "    if i == 0:\n",
    "        columns_list += ['avg_dbe','avg_ai','avg_nosc','avg_gfe']\n",
    "\n",
    "    for x in molec_class_no:\n",
    "        if i == 0: columns_list.append(x.lower().replace(' ','_'))\n",
    "        meta_data_dict[name].append(molec_class_no[x][i])\n",
    "\n",
    "meta_data_df = pd.DataFrame(data=meta_data_dict.values(),index=meta_data_dict.keys(),columns=columns_list)\n",
    "\n",
    "meta_data_path = f'{processed_csv_data_dir}/meta_data'\n",
    "meta_data_df.to_csv(csv_date_path(meta_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
